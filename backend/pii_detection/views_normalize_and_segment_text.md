# 文本标准化与 LTP 分词处理规则

## 概述
本文档同步自 `backend/pii_detection/views.py` 现有实现，说明标准化与分词的真实执行流程与规则。

### 流程总览
1. 文本标准化（基础清理 → 规范化 → 分句与句内规整 → 可选医学单位/符号标准化）
2. 分词与后处理（空格硬切分 → LTP 分词 → 标点清理与医学用药合并）
3. 输出与保存（结构化字符串与空格分隔文本，保存调试样例）

---

## 文本标准化（normalize_text）

### A. 预处理与保护
- HTML 标签清理：仅移除以字母开头的有效标签（`</?\s*[a-zA-Z][^>]*>`），避免把普通文本如 `<文本>` 误删。
- 噪音字符清理：连续 `@/#/*`（3 个以上）移除。
- 科学计数法保护：如 `11.5×10⁹/L` 用占位符临时保护，后续再还原。
- 性别符号：`♂`→`男`，`♀`→`女`。
- 乘号折叠：连续 `××…` 折叠为单个 `×`。
- 立方单位保护：将 `mm³/cm³/m³`（含 `/mm³` 等）在 NFKC 前转换为 `mm^3/cm^3/m^3`，避免 `³` 被标准化为 `3`。

### B. 标点转空格（带时间保护）
- 保护时间串（`HH:MM`/`HH:MM:SS`，支持 AM/PM）为占位符，避免冒号被替换。
- 将具有分词作用的符号统一替换为空格：冒号（`:`/`：`）、单双引号、各类括号（`()（）[]【】`）。
- 恢复时间占位符。

### C. 字符与空白规范
- Unicode 标准化：NFKC。
- 换行归一：`\r\n` / `\r` → `\n`。
- 空白合并：统一中间空白与行首尾空白。

### D. 标点与数字
- 重复标点折叠：成串 `！！/？？/；；` 等收敛为单个。
- 英文逗号统一为中文逗号 `，`。
- 数字中的千分位逗号去除：`15,600` → `15600`。
- 页码去除：`第 X 页`、`Page X`。

### E. 繁简转换
- 使用 OpenCC：繁体 → 简体。

### F. 句子级处理（_process_sentences）
- 分句依据：`。！？；?!;`、省略号（`…`/`...`）、换行。
- 句内处理：
  - 逗号统一为中文 `，`。
  - 中文括号临时替换为英文括号保护（后续清理阶段会去除括号类）。
  - 再次保护时间串，随后移除需清理的句内标点（配置中的括号/引号/方括号等），最后恢复时间串。
  - 日期解析与统一：使用 `dateutil.parser` 解析多种中英文日期，标准化为 `YYYY-MM-DD`。
  - 数字间连字符清理：如数值-数值中的连接符去除（仅在数字之间）。
  - 多空格压缩为单空格。
- 标准化文本输出格式：返回形如 `['句1','句2',...]` 的字符串。

### G. 可选：医学单位/符号标准化（spaCy PhraseMatcher）
- 前置条件：环境可用时启用；先做“单位标准化”，再做“符号语义替换”；单位内符号不替换。
- 单位映射：如 `μg/mL`/`ug/mL`→`μg/mL`，`μL/uL`→`μL`，`×10⁹/L`→`10^9/L`，`mmHg` 保持等。
- 符号语义：如 `↑/↑↑/↓/…` → 可读含义（高于/显著高于/低于等）。
- 字母符号（`H/L/N`）进行上下文校验（数值前后或医学语境）以降低误判。

---

## 分词与后处理（tokenize_and_segment）

### A. 空格硬切分 + LTP 分词
- 先按空格把句子切为片段（空格作为硬边界）。
- 对每个片段调用 LTP `cws` 分词并合并结果。

### B. 分词后清理（保留时间冒号）
- 若 token 匹配时间正则，保留冒号，仅移除括号/引号/方括号等。
- 其它 token：移除空白、冒号、单双引号、各类括号等具有分词作用的符号。

### C. 医学用药规则合并（_merge_medical_terms）
- 目标：提高剂量表达/单位限定的连贯性，不做“别名映射”，仅限结构合并。
- 单位集合（匹配小写/原样）：`mg, g, μg, ug, mcg, kg, ml, l, iu, u, ul, μl, gtt, 片, 粒, 袋, 支, 滴` 等。
- 频次/途径集合用于标记为小写（不合并）：`qd, bid, tid, qid, qod, qhs, hs, q6h, q8h, ...` 与 `po, iv, im, sc, sl, pr, top, inh, ...`。
- 合并规则：
  - 数字+单位：`['0.2','g','tid','po']` → `['0.2g','tid','po']`
  - 单位/限定：`['mg','/','kg']` → `['mg/kg']`；限定归一如 `m²/m2→m^2`，`hr→h`，`day→d`。
- 频次/途径：保留为独立 token，并统一为小写。

### D. 输出与保存
- 结构化文本：每句的 token 序列以 `['a','b']` 形式拼接；拼合后返回与日志打印。

---

## 文件解析（支持的输入）
- `.txt`：按 UTF-8 读取。
- `.docx`：python-docx 提取段落文本。
- `.pdf`：PyPDF2 逐页提取文本（依赖 PDF 结构质量）。

---

## 与评估脚本的配合
- 评估脚本默认使用标准化后的句子 → 空格硬切分 → LTP 分词 → 医学合并 的最终 tokens。
- 评估提供两套指标：
  - 常用：切分边界法（字符级边界 P/R/F1/Acc），更可信；需人工与自动在“去空格串”一致。
  - 参考：集合对比（P/R/F1/IoU），对词面差异更敏感。
